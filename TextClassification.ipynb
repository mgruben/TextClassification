{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "This notebook is intended to showcase a text classification proof-of-concept model, developed in TensorFlow.\n",
    "\n",
    "The dataset used for this notebook is the [Cornell Movie Review dataset](http://www.cs.cornell.edu/people/pabo/movie-review-data/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration and Analysis\n",
    "First, let's load our dataset into a `pandas` dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/cornell_movie_review.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get an idea of what the dataset looks like here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pos</td>\n",
       "      <td>films adapted from comic books have had plenty...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pos</td>\n",
       "      <td>every now and then a movie comes along from a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pos</td>\n",
       "      <td>you've got mail works alot better than it dese...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pos</td>\n",
       "      <td>\" jaws \" is a rare film that grabs your atten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>pos</td>\n",
       "      <td>moviemaking is a lot like being the general ma...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                             review\n",
       "id                                                         \n",
       "1    pos  films adapted from comic books have had plenty...\n",
       "2    pos  every now and then a movie comes along from a ...\n",
       "3    pos  you've got mail works alot better than it dese...\n",
       "4    pos   \" jaws \" is a rare film that grabs your atten...\n",
       "5    pos  moviemaking is a lot like being the general ma..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmm, it looks like **review** can't fully fit in the above table.  \n",
    "Let's grab the first review (1-indexed!) and see what it looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'films adapted from comic books have had plenty of success , whether they\\'re about superheroes ( batman , superman , spawn ) , or geared toward kids ( casper ) or the arthouse crowd ( ghost world ) , but there\\'s never really been a comic book like from hell before .  for starters , it was created by alan moore ( and eddie campbell ) , who brought the medium to a whole new level in the mid \\'80s with a 12-part series called the watchmen .  to say moore and campbell thoroughly researched the subject of jack the ripper would be like saying michael jackson is starting to look a little odd .  the book ( or \" graphic novel , \" if you will ) is over 500 pages long and includes nearly 30 more that consist of nothing but footnotes .  in other words , don\\'t dismiss this film because of its source .  if you can get past the whole comic book thing , you might find another stumbling block in from hell\\'s directors , albert and allen hughes .  getting the hughes brothers to direct this seems almost as ludicrous as casting carrot top in , well , anything , but riddle me this : who better to direct a film that\\'s set in the ghetto and features really violent street crime than the mad geniuses behind menace ii society ?  the ghetto in question is , of course , whitechapel in 1888 london\\'s east end .  it\\'s a filthy , sooty place where the whores ( called \" unfortunates \" ) are starting to get a little nervous about this mysterious psychopath who has been carving through their profession with surgical precision .  when the first stiff turns up , copper peter godley ( robbie coltrane , the world is not enough ) calls in inspector frederick abberline ( johnny depp , blow ) to crack the case .  abberline , a widower , has prophetic dreams he unsuccessfully tries to quell with copious amounts of absinthe and opium .  upon arriving in whitechapel , he befriends an unfortunate named mary kelly ( heather graham , say it isn\\'t so ) and proceeds to investigate the horribly gruesome crimes that even the police surgeon can\\'t stomach .  i don\\'t think anyone needs to be briefed on jack the ripper , so i won\\'t go into the particulars here , other than to say moore and campbell have a unique and interesting theory about both the identity of the killer and the reasons he chooses to slay .  in the comic , they don\\'t bother cloaking the identity of the ripper , but screenwriters terry hayes ( vertical limit ) and rafael yglesias ( les mis ? rables ) do a good job of keeping him hidden from viewers until the very end .  it\\'s funny to watch the locals blindly point the finger of blame at jews and indians because , after all , an englishman could never be capable of committing such ghastly acts .  and from hell\\'s ending had me whistling the stonecutters song from the simpsons for days ( \" who holds back the electric car/who made steve guttenberg a star ? \" ) .  don\\'t worry - it\\'ll all make sense when you see it .  now onto from hell\\'s appearance : it\\'s certainly dark and bleak enough , and it\\'s surprising to see how much more it looks like a tim burton film than planet of the apes did ( at times , it seems like sleepy hollow 2 ) .  the print i saw wasn\\'t completely finished ( both color and music had not been finalized , so no comments about marilyn manson ) , but cinematographer peter deming ( don\\'t say a word ) ably captures the dreariness of victorian-era london and helped make the flashy killing scenes remind me of the crazy flashbacks in twin peaks , even though the violence in the film pales in comparison to that in the black-and-white comic .  oscar winner martin childs\\' ( shakespeare in love ) production design turns the original prague surroundings into one creepy place .  even the acting in from hell is solid , with the dreamy depp turning in a typically strong performance and deftly handling a british accent .  ians holm ( joe gould\\'s secret ) and richardson ( 102 dalmatians ) log in great supporting roles , but the big surprise here is graham .  i cringed the first time she opened her mouth , imagining her attempt at an irish accent , but it actually wasn\\'t half bad .  the film , however , is all good .  2 : 00 - r for strong violence/gore , sexuality , language and drug content '"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['review'][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow, that's a lengthy review.  \n",
    "Let's check how many reviews there are in the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [Cornell Movie Review dataset](http://www.cs.cornell.edu/people/pabo/movie-review-data/) is divided into positive and negative reviews.  \n",
    "Let's check how many positive, and how many negative, reviews there are in this dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f751d87f748>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f751d8d8f28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['label'].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excellent, the dataset is already balanced.  \n",
    "Having a balanced dataset makes it easier to train a deep learning model, because it's less likely that the model will focus on one of the classes, and ignore the other.\n",
    "\n",
    "Now, let's see what the distribution of review lengths is, in numbers of characters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f751d87f6d8>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f751d8b7128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['review'].apply(len).hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, there are some much longer reviews in this dataset than the ~4,000 character review above, but most of them are under 6,000 characters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "The problem we are trying to solve here is called **sentiment analysis**, that is, whether the given text is positive or negative.\n",
    "\n",
    "More broadly, this is a type of machine learning problem known as classification.\n",
    "\n",
    "There are numerous different ways to think about the above dataset.  \n",
    "We can think of it as a collection of characters, a sequence of characters, a collection of words, or a sequence of words.  \n",
    "It turns out that the sequence-of-words approach has gotten good results on sentiment analysis problems, so let's think about the above dataset in those terms.\n",
    "\n",
    "Let's consider another review in the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'moviemaking is a lot like being the general manager of an nfl team in the post-salary cap era -- you\\'ve got to know how to allocate your resources .  every dollar spent on a free-agent defensive tackle is one less dollar than you can spend on linebackers or safeties or centers .  in the nfl , this leads to teams like the detroit lions , who boast a superstar running back with a huge contract , but can only field five guys named herb to block for him .  in the movies , you end up with films like \" spawn \" , with a huge special-effects budget but not enough money to hire any recognizable actors .  jackie chan is the barry sanders of moviemaking .  he spins and darts across the screen like sanders cutting back through the defensive line .  watching jackie in operation condor as he drives his motorcycle through the crowded streets of madrid , fleeing an armada of pursuers in identical black compact cars , is reminiscent of sanders running for daylight with the chicago bears in hot pursuit , except that sanders doesn\\'t have to worry about rescuing runaway baby carriages .  but like the lions star , jackie doesn\\'t have anybody to block for him .  almost every cent that\\'s invested in a jackie chan movie goes for stunts , and as chan does his own stunts , the rest of the money goes to pay his hospital bills .  this leaves about 75 cents to pay for things like directors ( chan directs ) , scripts and dubbing and supporting characters , not to mention the hideous title sequence .  this also explains why the movie was shot in odd places like morocco and spain .   ( chan\\'s first release in this country , \" rumble in the bronx \" , was supposedly set in new york , but was filmed in vancouver , and in the chase scenes the canadian rockies are clearly visible . )  heck , jackie doesn\\'t even have enough money for a haircut , looks like , much less a personal hairstylist .  in condor , chan plays the same character he\\'s always played , himself , a mixture of bruce lee and tim allen , a master of both kung-fu and slapstick-fu .  jackie is sent by the un to retrieve a cache of lost nazi gold in the north african desert , and is chased by a horde of neo-nazi sympathizers and two stereotypical arabs ( one of the things i like about jackie chan movies : no political correctness ) .  he is joined by three women , who have little to do except scream , \" jackie , save us ! \" , and misuse firearms .  the villain is an old nazi whose legs were broken in the secret base so that he has to be carried everywhere , and he\\'s more pathetic than evil .  en route , we have an extended motorcycle chase scene , a hilarious fight in the moroccan version of motel 6 with the neo-nazis , and two confrontations with savage natives .  once at the secret desert base , there is a long chop-socky sequence , followed by the film\\'s centerpiece , a wind-tunnel fight that\\'s even better than the one in face/off .  this is where the money was spent , on well-choreographed kung-fu sequences , on giant kevlar hamster balls , on smashed-up crates of bananas , and on scorpions .  ignore the gaping holes in the plot ( how , exactly , if the villain\\'s legs were broken , did he escape from the secret nazi base , and why didn\\'t he take the key with him ? ) .  don\\'t worry about the production values , or what , exactly , the japanese girl was doing hitchhiking across the sahara .  just go see the movie .  operation condor has pretentions of being a \" raiders of the lost ark \" knockoff , but one wonders what jackie could do with the raiders franchise blocking for him -- with a lawrence kazdan screenplay , a john williams score , spielberg directing and george lucas producing , condor might be an a+ movie .  however , you\\'ve got to go with what you\\'ve got , and what you\\'ve got in jackie chan is something special -- a talent that mainstream hollywood should , could , and ought to utilize . '"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['review'][5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization\n",
    "What we would like to do is to turn the text above into a fixed-length sequence of numbers, which is what our TensorFlow model will expect in order to train on.\n",
    "\n",
    "The basic idea behind working with text data is that we want to create a number for each unique \"token\" that we see, then we can just substitute a \"token\"'s number for the token itself, and arrive at a fixed-length sequence of numbers for TensorFlow to work with.\n",
    "\n",
    "As can be seen above, it's not just words that are present, but also punctuation.  \n",
    "\n",
    "Thankfully, the [natural language toolkit](http://www.nltk.org/) is excellent at turning a string of text into a list of tokens.\n",
    "\n",
    "Let's see how it behaves on the above review:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['moviemaking',\n",
       " 'is',\n",
       " 'a',\n",
       " 'lot',\n",
       " 'like',\n",
       " 'being',\n",
       " 'the',\n",
       " 'general',\n",
       " 'manager',\n",
       " 'of']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.tokenize.word_tokenize(df['review'][5])[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above is perfectly sufficient tokenization for our purposes.  \n",
    "Perhaps it could be improved upon slightly, but this breaks up our review into enough unique tokens that our model will be able to learn which ones to use and which ones to discount (more on that in the [Architecture](#Model-Architecture) section)\n",
    "\n",
    "Now, let's create a set of all the words in all of the reviews in our dataset.  \n",
    "We will use this set to create a lookup table of tokens to their \"IDs\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_word_set = set()\n",
    "for r in df['review']:\n",
    "    review_word_set.update(nltk.tokenize.word_tokenize(r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46716"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(review_word_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excellent, in our 2,000-review dataset, only some ~47,000 unique \"tokens\" have been used.  \n",
    "## Token Encoding\n",
    "Now, let's use this set to assign IDs to our tokens, so that we can easily go from a token to its ID, and vice versa.\n",
    "\n",
    "First though, let's reserve ID `0` for reasons that will become clear in the [Padding](#Padding) section below, and start at ID `1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_id = {word: i for i, word in enumerate(review_word_set, 1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'benji-like': 1,\n",
       " 'voges': 2,\n",
       " 'valderrama': 3,\n",
       " 'lark': 4,\n",
       " 'mandel': 5,\n",
       " 'manuscript': 6,\n",
       " 'addresses': 7,\n",
       " 'retinal': 8,\n",
       " 'succumbed': 9,\n",
       " \"'judge\": 10,\n",
       " 'couture': 11,\n",
       " 'ex-champion': 12,\n",
       " 'pre-intellectualizing': 13,\n",
       " 'degrees': 14,\n",
       " 'husk': 15,\n",
       " 'caribbean': 16,\n",
       " 'book': 17,\n",
       " 'onwards': 18,\n",
       " 'syd': 19,\n",
       " 'abolish': 20,\n",
       " '_the': 21,\n",
       " 'uneasy': 22,\n",
       " 'reflexivity': 23,\n",
       " 'lie': 24,\n",
       " 'remaning': 25,\n",
       " 'lesbianism': 26,\n",
       " 'caron': 27,\n",
       " 'deities': 28,\n",
       " 'deconstruct': 29,\n",
       " 'assisting': 30,\n",
       " 'staros': 31,\n",
       " 'committee': 32,\n",
       " 'intertwines': 33,\n",
       " 'edward': 34,\n",
       " 'lopez': 35,\n",
       " 'harvesting': 36,\n",
       " 'reichle': 37,\n",
       " 'shaker': 38,\n",
       " 'klein': 39,\n",
       " 'never-before-seen': 40,\n",
       " 'wahlberg': 41,\n",
       " 'interview': 42,\n",
       " 'candle-lighting': 43,\n",
       " 'tennille': 44,\n",
       " 'bereaved': 45,\n",
       " 'absence': 46,\n",
       " 'brainy': 47,\n",
       " 'meany': 48,\n",
       " 'toothy': 49,\n",
       " 'unwed': 50,\n",
       " 'tips': 51,\n",
       " 'rasping': 52,\n",
       " 'loosing': 53,\n",
       " 'avenged': 54,\n",
       " 'oprah': 55,\n",
       " 'tania': 56,\n",
       " 'kevin': 57,\n",
       " 'once-simple': 58,\n",
       " 'cops-on-the-trail-of-serial-killer': 59,\n",
       " 'marksman': 60,\n",
       " 'pronto': 61,\n",
       " 'donate': 62,\n",
       " 'jane': 63,\n",
       " 'permeated': 64,\n",
       " 'one-tone': 65,\n",
       " 'kings': 66,\n",
       " 'hoist': 67,\n",
       " 'depraved': 68,\n",
       " 'populous': 69,\n",
       " 'conor': 70,\n",
       " 'kidnapper/killer': 71,\n",
       " 're-drawn': 72,\n",
       " 'leguizimo': 73,\n",
       " 'wo-ping': 74,\n",
       " 'tidyman': 75,\n",
       " 'hyper-real': 76,\n",
       " 'separates': 77,\n",
       " 'outdated': 78,\n",
       " 'funny': 79,\n",
       " 'irritates': 80,\n",
       " 'dumbest': 81,\n",
       " 'roma': 82,\n",
       " 'movie/tv': 83,\n",
       " 'boyish': 84,\n",
       " '29-year-old': 85,\n",
       " 'tribe': 86,\n",
       " 'larger-theme': 87,\n",
       " 'funneled': 88,\n",
       " 'seeked': 89,\n",
       " 'kung': 90,\n",
       " 'vastness': 91,\n",
       " 'heart-warming': 92,\n",
       " 'diplomat': 93,\n",
       " 'procreate': 94,\n",
       " 'eye-catcher': 95,\n",
       " 'ex-new': 96,\n",
       " 'serbedzija': 97,\n",
       " 'sacrificing': 98,\n",
       " 'jere': 99,\n",
       " 'penn': 100,\n",
       " 'successive': 101,\n",
       " 'drying': 102,\n",
       " 'assitance': 103,\n",
       " 'goldbergesque': 104,\n",
       " 'wanker': 105,\n",
       " 'filer': 106,\n",
       " 'scare-thrillers': 107,\n",
       " 'babies': 108,\n",
       " 'guevera': 109,\n",
       " 'tread': 110,\n",
       " 'navarro': 111,\n",
       " 'roshomon': 112,\n",
       " 'thrift': 113,\n",
       " 'mannerisms': 114,\n",
       " 'noticing': 115,\n",
       " 'scraping': 116,\n",
       " 'retched': 117,\n",
       " 'dialect': 118,\n",
       " 'proceedings': 119,\n",
       " 'space-faring': 120,\n",
       " 'dorn': 121,\n",
       " 'dorky-looking': 122,\n",
       " 'istvan': 123,\n",
       " 'manifesting': 124,\n",
       " 'seemingly-endless': 125,\n",
       " 'nonfans': 126,\n",
       " 'revenge-for-hire': 127,\n",
       " 'convinced': 128,\n",
       " 'pyre': 129,\n",
       " 'bernsen': 130,\n",
       " 'naturalness': 131,\n",
       " 'athos': 132,\n",
       " 'winces': 133,\n",
       " '12-year': 134,\n",
       " 'hark': 135,\n",
       " 'envisioned': 136,\n",
       " 'anti-apartheid': 137,\n",
       " 'wendt': 138,\n",
       " 'noctis': 139,\n",
       " 'lama': 140,\n",
       " 'abnormal': 141,\n",
       " 'jewelry': 142,\n",
       " 'flare': 143,\n",
       " 'violations': 144,\n",
       " 'ethnic': 145,\n",
       " 'begging': 146,\n",
       " 'braddock': 147,\n",
       " 'took': 148,\n",
       " 'darwinism-': 149,\n",
       " 'terribly': 150,\n",
       " 'yatf': 151,\n",
       " 'wither': 152,\n",
       " 'concoction': 153,\n",
       " 'comprehendably': 154,\n",
       " 'lamppost': 155,\n",
       " 'imaginations': 156,\n",
       " 'talent': 157,\n",
       " 'each': 158,\n",
       " 'bedroom': 159,\n",
       " 'redone': 160,\n",
       " 'benefactors': 161,\n",
       " 'mulroney': 162,\n",
       " 'deceptions': 163,\n",
       " 'out-of-nowhere': 164,\n",
       " 'barbs': 165,\n",
       " 'mousetrap': 166,\n",
       " '`bonnie': 167,\n",
       " 'skarsgaard': 168,\n",
       " 'uprising': 169,\n",
       " 'eternally': 170,\n",
       " 'happenning': 171,\n",
       " 'possessions': 172,\n",
       " 'codger': 173,\n",
       " 'straightest': 174,\n",
       " 'light-saber': 175,\n",
       " 'reviewer': 176,\n",
       " 'unextraordinary': 177,\n",
       " 'gunfire': 178,\n",
       " 'princesses': 179,\n",
       " 'romantically': 180,\n",
       " 'geri': 181,\n",
       " 'catfights': 182,\n",
       " 'mum': 183,\n",
       " 'schoolchildren': 184,\n",
       " 'ac3': 185,\n",
       " 'bouyant': 186,\n",
       " 'choses': 187,\n",
       " 'romancing': 188,\n",
       " 'someone-else': 189,\n",
       " 'duffle': 190,\n",
       " 'sables': 191,\n",
       " 'dig': 192,\n",
       " 'harrigan': 193,\n",
       " 'nonchalant': 194,\n",
       " 'colour': 195,\n",
       " 'tycoon/villain': 196,\n",
       " 'hurricanes': 197,\n",
       " 'beaudene': 198,\n",
       " 'bijou': 199,\n",
       " 'firth': 200,\n",
       " 'excusable': 201,\n",
       " 'wishful': 202,\n",
       " 'projecting': 203,\n",
       " 'farces': 204,\n",
       " 'unhappy': 205,\n",
       " 'greenaway': 206,\n",
       " 'inky': 207,\n",
       " 'seduces': 208,\n",
       " 'self-worth': 209,\n",
       " 'crusades': 210,\n",
       " 'living-and-breathing': 211,\n",
       " 'forbes': 212,\n",
       " 'prolonged': 213,\n",
       " 'zeltser': 214,\n",
       " 'sabotaged': 215,\n",
       " 'moons': 216,\n",
       " 'unsatisying': 217,\n",
       " 'complicity': 218,\n",
       " 'deposit': 219,\n",
       " 'howard=92s': 220,\n",
       " 'warner-brothers-coyote-fall-off-the-cliff': 221,\n",
       " 'give': 222,\n",
       " 'pastoral': 223,\n",
       " 'heart-tug': 224,\n",
       " 'whispered': 225,\n",
       " 'commentary': 226,\n",
       " 'snowstorm': 227,\n",
       " 'cake-walk': 228,\n",
       " 'post-industrial': 229,\n",
       " 'superhuman': 230,\n",
       " 'missive': 231,\n",
       " 'blatherings': 232,\n",
       " 'sail': 233,\n",
       " 'dragonlike': 234,\n",
       " 'utility': 235,\n",
       " \"'titanic\": 236,\n",
       " 'downplaying': 237,\n",
       " 'wander': 238,\n",
       " 'one-night': 239,\n",
       " 'nonfiction': 240,\n",
       " 'understand': 241,\n",
       " 'rio': 242,\n",
       " 'therapy': 243,\n",
       " 'always-reliable': 244,\n",
       " 'compassion': 245,\n",
       " 'vestiges': 246,\n",
       " 'raided': 247,\n",
       " 'share': 248,\n",
       " 'half-bad': 249,\n",
       " 'lucidity': 250,\n",
       " 'slawomir': 251,\n",
       " 'obeys': 252,\n",
       " 'tommy': 253,\n",
       " 'expelled': 254,\n",
       " 'foisted': 255,\n",
       " 'stella': 256,\n",
       " 'like_blade': 257,\n",
       " 'inelegantly': 258,\n",
       " 'hank': 259,\n",
       " 'conversations': 260,\n",
       " 'frivilous': 261,\n",
       " 'drumroll': 262,\n",
       " 'barrel': 263,\n",
       " 'extermination': 264,\n",
       " 'rigour': 265,\n",
       " 'chainsaws': 266,\n",
       " 'surfboards': 267,\n",
       " 'quandary': 268,\n",
       " 'fullyloaded': 269,\n",
       " 'ninth': 270,\n",
       " 'ole': 271,\n",
       " 'deviating': 272,\n",
       " 'formulaic': 273,\n",
       " 'tumbleweeds': 274,\n",
       " 'tolerating': 275,\n",
       " 'calculated': 276,\n",
       " 'statues': 277,\n",
       " 'whales/triangle': 278,\n",
       " 'gassner': 279,\n",
       " 'must-sees': 280,\n",
       " 'inconsistencies': 281,\n",
       " 'australian': 282,\n",
       " 'analyzes': 283,\n",
       " 'especially': 284,\n",
       " 'obsessive/compulsive': 285,\n",
       " 'comedies': 286,\n",
       " 'rebounding': 287,\n",
       " 'mack': 288,\n",
       " 'long-long': 289,\n",
       " 'flinging': 290,\n",
       " 'bussing': 291,\n",
       " 'hoblit': 292,\n",
       " 'welfare': 293,\n",
       " 'excepting': 294,\n",
       " 'nostromo': 295,\n",
       " 'deleting': 296,\n",
       " 'roxy': 297,\n",
       " 'wreaks': 298,\n",
       " 'battering': 299,\n",
       " '`sophisticated': 300,\n",
       " 'agony': 301,\n",
       " 'legal-drug': 302,\n",
       " 'railings': 303,\n",
       " 'lasting': 304,\n",
       " 'smacked': 305,\n",
       " 'sibling': 306,\n",
       " 'duties': 307,\n",
       " 'yorick': 308,\n",
       " 'gyrations': 309,\n",
       " 'mcglone': 310,\n",
       " 'developer': 311,\n",
       " 'disguise': 312,\n",
       " 'over-extended': 313,\n",
       " 'mattes': 314,\n",
       " 'psychotherapy': 315,\n",
       " 'grades': 316,\n",
       " 'blane': 317,\n",
       " 'heberle': 318,\n",
       " 'pulpy': 319,\n",
       " 'kurtwood': 320,\n",
       " 'grier': 321,\n",
       " 'snub': 322,\n",
       " 'hitmen': 323,\n",
       " 'objectionable': 324,\n",
       " 'egar': 325,\n",
       " 'affirming': 326,\n",
       " 'apparitions': 327,\n",
       " 'loeb': 328,\n",
       " 'opposition': 329,\n",
       " 'certain': 330,\n",
       " 'cat-and-mouse': 331,\n",
       " 'carmel': 332,\n",
       " 'mood': 333,\n",
       " 'discordant': 334,\n",
       " 'brinkley': 335,\n",
       " 'linz': 336,\n",
       " 'yell': 337,\n",
       " 'raises': 338,\n",
       " 'trash-talking': 339,\n",
       " 'uphill': 340,\n",
       " 'psychotically': 341,\n",
       " 'depak': 342,\n",
       " 'grenier': 343,\n",
       " 'recipient': 344,\n",
       " 'venora': 345,\n",
       " 'unleashes': 346,\n",
       " 'deapens': 347,\n",
       " 'cathy': 348,\n",
       " 'glorious': 349,\n",
       " 'hootworthy': 350,\n",
       " 'man-animals': 351,\n",
       " 'hawtrey': 352,\n",
       " 'lili': 353,\n",
       " 'thang': 354,\n",
       " 'animatronics': 355,\n",
       " 'phi': 356,\n",
       " 'overlong': 357,\n",
       " 'exasperation': 358,\n",
       " 'keaton': 359,\n",
       " 'avenging': 360,\n",
       " 'reheal': 361,\n",
       " 'argonians': 362,\n",
       " 'shacking': 363,\n",
       " 'thereus': 364,\n",
       " 'seige': 365,\n",
       " 'wall': 366,\n",
       " 'antennae-like': 367,\n",
       " '35mm': 368,\n",
       " 'limon': 369,\n",
       " 'port': 370,\n",
       " 'potted': 371,\n",
       " 'fray': 372,\n",
       " 'automaton': 373,\n",
       " 'manouvering': 374,\n",
       " 'low-caliber': 375,\n",
       " 'self-deprecating': 376,\n",
       " 'daily': 377,\n",
       " 'battery-charging': 378,\n",
       " 'eloi': 379,\n",
       " 'deconstructs': 380,\n",
       " 'consummated': 381,\n",
       " 'mis-': 382,\n",
       " 'wilds': 383,\n",
       " 'curmudgeon': 384,\n",
       " 'sluts': 385,\n",
       " 'redoubtable': 386,\n",
       " 'absorbs': 387,\n",
       " 'prevent': 388,\n",
       " 'righting': 389,\n",
       " 'chat': 390,\n",
       " 'partnered': 391,\n",
       " 'joon': 392,\n",
       " 'barbarino': 393,\n",
       " 'verbatim': 394,\n",
       " 'soft-': 395,\n",
       " 'infallibility': 396,\n",
       " 'drugged-out': 397,\n",
       " 'reworkings': 398,\n",
       " 'sutton': 399,\n",
       " 'panoramas': 400,\n",
       " 'siphoned': 401,\n",
       " 'instant-gratification': 402,\n",
       " 'terk': 403,\n",
       " 'budgets': 404,\n",
       " 'connect-the-dots': 405,\n",
       " 'sleaziness': 406,\n",
       " 'pacha': 407,\n",
       " 'grader': 408,\n",
       " 'may': 409,\n",
       " '_casablanca_': 410,\n",
       " 'drug-induced': 411,\n",
       " 'institutes': 412,\n",
       " 'big-': 413,\n",
       " 'decay': 414,\n",
       " '19th-century': 415,\n",
       " 'criticisms': 416,\n",
       " 'sparing': 417,\n",
       " 'conservative': 418,\n",
       " 'contentiousness': 419,\n",
       " 'turgeon': 420,\n",
       " 'awhile': 421,\n",
       " 'sneeze': 422,\n",
       " 'structuring': 423,\n",
       " 'ratzenberger': 424,\n",
       " 'semester': 425,\n",
       " 'hollywood': 426,\n",
       " 'over-stylized': 427,\n",
       " 'longbaugh': 428,\n",
       " 'com/~corona/films/details/sw4': 429,\n",
       " '_in': 430,\n",
       " 'juliette': 431,\n",
       " 'deplorable': 432,\n",
       " 'regulations': 433,\n",
       " 'adores': 434,\n",
       " 'incoherence': 435,\n",
       " 'one-word': 436,\n",
       " 'tumbles': 437,\n",
       " 'cutouts': 438,\n",
       " 'hay': 439,\n",
       " 'unrated': 440,\n",
       " 'explantion': 441,\n",
       " 'indie-rock': 442,\n",
       " 'vartan': 443,\n",
       " 'dave-good': 444,\n",
       " 'tri-star': 445,\n",
       " 'rocket': 446,\n",
       " 'existent': 447,\n",
       " 'incisive': 448,\n",
       " 'thrilling': 449,\n",
       " 'bandies': 450,\n",
       " 're': 451,\n",
       " 'unlike': 452,\n",
       " 'moustached': 453,\n",
       " 'bateman': 454,\n",
       " 'streep': 455,\n",
       " 'foretold': 456,\n",
       " 'flaunt': 457,\n",
       " 'nebbish': 458,\n",
       " 'courthouse': 459,\n",
       " 'abides': 460,\n",
       " 'katzenberg': 461,\n",
       " 'fibe': 462,\n",
       " 'deathcamps': 463,\n",
       " 'gunned': 464,\n",
       " 'disco': 465,\n",
       " 'incompletely': 466,\n",
       " 'wormwoods': 467,\n",
       " 'grenade': 468,\n",
       " 'spader': 469,\n",
       " 'deux': 470,\n",
       " 'victims': 471,\n",
       " 'carjacking': 472,\n",
       " 'awright': 473,\n",
       " 'gigi': 474,\n",
       " 'bouquet': 475,\n",
       " 'lifespan': 476,\n",
       " 'boys': 477,\n",
       " 'culp': 478,\n",
       " 'xtdl': 479,\n",
       " 'roam': 480,\n",
       " 'barges': 481,\n",
       " 'doomsaying': 482,\n",
       " 'chit': 483,\n",
       " 'wright-penn': 484,\n",
       " '170': 485,\n",
       " 'kamikaze': 486,\n",
       " 'catalyst': 487,\n",
       " 'lip-smacking': 488,\n",
       " 'acres': 489,\n",
       " 'offed': 490,\n",
       " 'death-defying': 491,\n",
       " 'bottles': 492,\n",
       " 'stumbles': 493,\n",
       " 'fatboy': 494,\n",
       " 'street-wise': 495,\n",
       " 'crunchem': 496,\n",
       " 'disqualified': 497,\n",
       " 'uptown': 498,\n",
       " 'montage-backed': 499,\n",
       " 'rafts': 500,\n",
       " 'furry': 501,\n",
       " 'fanatically': 502,\n",
       " 'centre': 503,\n",
       " 'dian': 504,\n",
       " \"'psycho\": 505,\n",
       " 'crouched': 506,\n",
       " 'newlywed': 507,\n",
       " 'novicorp': 508,\n",
       " '11-year': 509,\n",
       " 'unmatched': 510,\n",
       " 'impolite': 511,\n",
       " 'charbanic': 512,\n",
       " 'lead-faced': 513,\n",
       " '10': 514,\n",
       " 'seeming': 515,\n",
       " 'kingston': 516,\n",
       " 'sims': 517,\n",
       " 'disguises': 518,\n",
       " 'frenetically': 519,\n",
       " 'medak': 520,\n",
       " 'massage': 521,\n",
       " 'swarm': 522,\n",
       " 'zephram': 523,\n",
       " 'agricultural': 524,\n",
       " 'expressionism': 525,\n",
       " 'astaire': 526,\n",
       " 'jackman': 527,\n",
       " 'snap-brim': 528,\n",
       " 'decades': 529,\n",
       " 'on-the-spot': 530,\n",
       " 'arrangement': 531,\n",
       " 'permanence': 532,\n",
       " 'cross': 533,\n",
       " 'computer-simulated': 534,\n",
       " 'nonsensical': 535,\n",
       " 'client': 536,\n",
       " 'criticize': 537,\n",
       " 'mcgoohan': 538,\n",
       " 'enwrapped': 539,\n",
       " 'abbreviated': 540,\n",
       " 'computer-assisted': 541,\n",
       " 'sleepy': 542,\n",
       " 'eastward': 543,\n",
       " 'cuz': 544,\n",
       " 'ape': 545,\n",
       " \"year's-open\": 546,\n",
       " 'protective': 547,\n",
       " 'hypnotically': 548,\n",
       " 'something-or-the-other': 549,\n",
       " 'fetishistic': 550,\n",
       " 'amrriage': 551,\n",
       " 'stirs': 552,\n",
       " 'paup': 553,\n",
       " 'erupts': 554,\n",
       " 'decoys': 555,\n",
       " 'tritt': 556,\n",
       " 'solomon': 557,\n",
       " 'annual': 558,\n",
       " 'dizzyingly': 559,\n",
       " 'satisfactory': 560,\n",
       " 'low-brow': 561,\n",
       " 'acknowledge': 562,\n",
       " 'beetles': 563,\n",
       " 'phrases': 564,\n",
       " 'chestnuts': 565,\n",
       " 'spaceship': 566,\n",
       " 'subjectivity': 567,\n",
       " 'simplistically': 568,\n",
       " 'winslett': 569,\n",
       " '_a': 570,\n",
       " 'outstripped': 571,\n",
       " 'reestablishing': 572,\n",
       " '-': 573,\n",
       " 'debates': 574,\n",
       " 'mystically': 575,\n",
       " 'bombay': 576,\n",
       " 'signal': 577,\n",
       " 'kowalski': 578,\n",
       " 'garnish': 579,\n",
       " 'singe': 580,\n",
       " 'motown': 581,\n",
       " 'campaign': 582,\n",
       " 'portia': 583,\n",
       " 'wincing': 584,\n",
       " 'sputtering': 585,\n",
       " 'wile': 586,\n",
       " 'knockoff': 587,\n",
       " 'raiment': 588,\n",
       " 'oriented': 589,\n",
       " 'writer/directors': 590,\n",
       " 'half-man': 591,\n",
       " 'stewardess': 592,\n",
       " 'pre-conceived': 593,\n",
       " \"'hollow\": 594,\n",
       " 'munchkin': 595,\n",
       " 'ignorable': 596,\n",
       " '23rd': 597,\n",
       " 'schumann': 598,\n",
       " 'jerusalem': 599,\n",
       " 'supporting': 600,\n",
       " 'set-up': 601,\n",
       " 'yim': 602,\n",
       " 'unempathetic': 603,\n",
       " 'maunau': 604,\n",
       " 'helgenberger': 605,\n",
       " '13-20': 606,\n",
       " 'rubber': 607,\n",
       " 'ergonomics': 608,\n",
       " 'adult': 609,\n",
       " 'corrects': 610,\n",
       " 'come-uppance': 611,\n",
       " 'lost': 612,\n",
       " 'german': 613,\n",
       " 'twenty-five': 614,\n",
       " 'carelessly': 615,\n",
       " 'wags': 616,\n",
       " 'smog': 617,\n",
       " 'calderon': 618,\n",
       " 'rolfe': 619,\n",
       " 'mourned': 620,\n",
       " 'irascible': 621,\n",
       " 'risking': 622,\n",
       " 'vapors': 623,\n",
       " 'previewed': 624,\n",
       " 're-delivering': 625,\n",
       " 'bewildering': 626,\n",
       " 'homefront': 627,\n",
       " 'far-side': 628,\n",
       " 'neutralize': 629,\n",
       " 'materialist': 630,\n",
       " 'sharing': 631,\n",
       " 'prejudiced': 632,\n",
       " 'necrophilia': 633,\n",
       " 'construed': 634,\n",
       " 'rustic': 635,\n",
       " 'fegan': 636,\n",
       " 'swigert': 637,\n",
       " 'walkers': 638,\n",
       " 'lurking': 639,\n",
       " 'wendkos': 640,\n",
       " 'terminate': 641,\n",
       " 'persecuted': 642,\n",
       " 'brigante': 643,\n",
       " 'fantasized': 644,\n",
       " 'fairy-tale': 645,\n",
       " 'semi-thorough': 646,\n",
       " 'miscommunicated': 647,\n",
       " 'slasher-movie': 648,\n",
       " 'myrick': 649,\n",
       " 'passport': 650,\n",
       " 'lowbrow': 651,\n",
       " 'double-camera': 652,\n",
       " 'noisily': 653,\n",
       " 'cassavettes': 654,\n",
       " 'sloppiest': 655,\n",
       " 'pounder': 656,\n",
       " 'separatist': 657,\n",
       " 'warehouse': 658,\n",
       " 'entertainingly': 659,\n",
       " 'called': 660,\n",
       " 'oppposed': 661,\n",
       " 'chipmunks': 662,\n",
       " 'vigil': 663,\n",
       " 'claw': 664,\n",
       " 'burnt-out': 665,\n",
       " 'wrong-side-of-the-tracks': 666,\n",
       " 'wrongdoing': 667,\n",
       " 'giveaway': 668,\n",
       " 'dissertations': 669,\n",
       " 'kari': 670,\n",
       " 'senile': 671,\n",
       " 'risk-taking': 672,\n",
       " 'malick': 673,\n",
       " 'overly-noisy': 674,\n",
       " 'unhappily': 675,\n",
       " 'comedies-': 676,\n",
       " 'helpfulness': 677,\n",
       " 'groaned': 678,\n",
       " 'smirky': 679,\n",
       " 'nifty': 680,\n",
       " 'dropout': 681,\n",
       " 'skirt': 682,\n",
       " 'probgram': 683,\n",
       " 'outacts': 684,\n",
       " 'well-deserving': 685,\n",
       " 'smug': 686,\n",
       " 'overcome': 687,\n",
       " 'saracastic': 688,\n",
       " 'quirky-but-realistic': 689,\n",
       " 'organization': 690,\n",
       " 'josef': 691,\n",
       " 'pigeonholing': 692,\n",
       " 'alluringly': 693,\n",
       " 'parading': 694,\n",
       " 'golden': 695,\n",
       " 'sales-pitch': 696,\n",
       " 'luhrman': 697,\n",
       " 'mohr': 698,\n",
       " 'one-celled': 699,\n",
       " 'sword': 700,\n",
       " 'sacrament': 701,\n",
       " 'blockbusters': 702,\n",
       " 'canna': 703,\n",
       " 'eaisly': 704,\n",
       " 'anxiety-ridden': 705,\n",
       " 'unusable': 706,\n",
       " 'horror-drama': 707,\n",
       " 'farmers': 708,\n",
       " 'sluizer': 709,\n",
       " 'miners': 710,\n",
       " 'howitt': 711,\n",
       " 'pos': 712,\n",
       " 'replacing': 713,\n",
       " 'fritz': 714,\n",
       " 'attachs': 715,\n",
       " 'conn': 716,\n",
       " 'dietl': 717,\n",
       " 're-connect': 718,\n",
       " 'cringes': 719,\n",
       " 'breached': 720,\n",
       " 'politicos': 721,\n",
       " 'vampire-films': 722,\n",
       " 'neo-noirs': 723,\n",
       " 'proposes': 724,\n",
       " 'gere\\x12s': 725,\n",
       " 'runner-esque': 726,\n",
       " 'noooo': 727,\n",
       " 'supervisor': 728,\n",
       " 'love-dependent': 729,\n",
       " 'fandom': 730,\n",
       " 'teen-dominated': 731,\n",
       " 'splatter': 732,\n",
       " 'humbert': 733,\n",
       " 'pertains': 734,\n",
       " 'clarence': 735,\n",
       " 'foible': 736,\n",
       " 'tough-talking': 737,\n",
       " \"o'day\": 738,\n",
       " 'experiencing': 739,\n",
       " 'chainsmoking': 740,\n",
       " 'dredges': 741,\n",
       " 'paramedic': 742,\n",
       " 'zhuangzhuang': 743,\n",
       " 'lined': 744,\n",
       " 'love-interest': 745,\n",
       " 'auditorium': 746,\n",
       " 'good-guy': 747,\n",
       " 'gunshots': 748,\n",
       " 'lean': 749,\n",
       " 'world': 750,\n",
       " 'analyst': 751,\n",
       " 'juices': 752,\n",
       " 'blind': 753,\n",
       " 'reforms': 754,\n",
       " 'cassanova-ness': 755,\n",
       " 'anti-matter': 756,\n",
       " 'go-round': 757,\n",
       " 'festive': 758,\n",
       " 'influence': 759,\n",
       " 'appliances': 760,\n",
       " 'adrianne': 761,\n",
       " 'rifle-ly': 762,\n",
       " 'oed': 763,\n",
       " 'thumbs': 764,\n",
       " 'signatures': 765,\n",
       " 'campell': 766,\n",
       " '1930s': 767,\n",
       " 'stereoscopic': 768,\n",
       " 'lot': 769,\n",
       " 'once-married-but-now-estranged': 770,\n",
       " 'glamorous': 771,\n",
       " 'barker': 772,\n",
       " 'tasteless': 773,\n",
       " 'disbelieving': 774,\n",
       " 'artificial': 775,\n",
       " 'up-beat': 776,\n",
       " 'inconveniences': 777,\n",
       " 'sobel': 778,\n",
       " 'hooper': 779,\n",
       " 'goat': 780,\n",
       " 'movies': 781,\n",
       " 'month-long': 782,\n",
       " 'karloff': 783,\n",
       " 'protectionist': 784,\n",
       " 'storyboard-to-scene': 785,\n",
       " 'pardon': 786,\n",
       " '+3': 787,\n",
       " 'mare': 788,\n",
       " 'e': 789,\n",
       " 'babboons': 790,\n",
       " 'bio-mechanical': 791,\n",
       " '/cinematographer/editor': 792,\n",
       " 'rain-soaked': 793,\n",
       " 'composer/lyricist': 794,\n",
       " 'camerons': 795,\n",
       " 'hypocritical': 796,\n",
       " \"'original\": 797,\n",
       " 'pledges': 798,\n",
       " 'wittliff': 799,\n",
       " '3/4': 800,\n",
       " 'breakdances': 801,\n",
       " '1812': 802,\n",
       " 'stake': 803,\n",
       " '_star': 804,\n",
       " 'interrotron': 805,\n",
       " 'play/movie': 806,\n",
       " 'personal': 807,\n",
       " 'eye-popper': 808,\n",
       " 'loners': 809,\n",
       " 'charlatans': 810,\n",
       " 'mentionable': 811,\n",
       " 'nether': 812,\n",
       " 'boggles': 813,\n",
       " 'near-pornographic': 814,\n",
       " 'gershwin': 815,\n",
       " 'division': 816,\n",
       " 'scrutinize': 817,\n",
       " 'schoolteacher': 818,\n",
       " 'whoever': 819,\n",
       " 'rooker': 820,\n",
       " 'manage': 821,\n",
       " \"o'toole\": 822,\n",
       " 'consideration': 823,\n",
       " 'ren': 824,\n",
       " 'mains': 825,\n",
       " '_roxbury_': 826,\n",
       " 'spunk': 827,\n",
       " 'rapping': 828,\n",
       " 'half-million': 829,\n",
       " 'wiseguys': 830,\n",
       " 'howled': 831,\n",
       " 'father/david': 832,\n",
       " 'vessels': 833,\n",
       " 'blatancy': 834,\n",
       " 'outside-in': 835,\n",
       " 'heinous': 836,\n",
       " 'combat': 837,\n",
       " 'dubarry': 838,\n",
       " 'interlinked': 839,\n",
       " 'goldeneye': 840,\n",
       " 'wowing': 841,\n",
       " 'overachieving': 842,\n",
       " 'interrogative': 843,\n",
       " 'upright': 844,\n",
       " 'profundities': 845,\n",
       " 'catch-22': 846,\n",
       " 'roan': 847,\n",
       " 'ineffectuality': 848,\n",
       " 'invigorate': 849,\n",
       " 'lianna': 850,\n",
       " 'merle': 851,\n",
       " 'legged': 852,\n",
       " 'non-existant': 853,\n",
       " 'wehrmacht': 854,\n",
       " 'flop-house': 855,\n",
       " 'brauvara': 856,\n",
       " 'strocker': 857,\n",
       " 'flaky': 858,\n",
       " 'paraphrase': 859,\n",
       " 'defends': 860,\n",
       " 'sexiest': 861,\n",
       " 'distrusts': 862,\n",
       " 'clashing': 863,\n",
       " 'cronenberg': 864,\n",
       " 'giacomo': 865,\n",
       " 'tee-shirt': 866,\n",
       " 'overcooked': 867,\n",
       " 'schillings': 868,\n",
       " 'annoys': 869,\n",
       " 'cluttered': 870,\n",
       " 'misses/catches': 871,\n",
       " 'crichton': 872,\n",
       " 'uncomfortable': 873,\n",
       " 'resolutions': 874,\n",
       " 'harron': 875,\n",
       " 'headquarters': 876,\n",
       " 'up': 877,\n",
       " 'darkened': 878,\n",
       " 'hara-kiri': 879,\n",
       " 'blended': 880,\n",
       " 'prohibition': 881,\n",
       " 'messenger': 882,\n",
       " 'pools': 883,\n",
       " 'narc': 884,\n",
       " 'woof': 885,\n",
       " 'computech': 886,\n",
       " 'we\\x12ll': 887,\n",
       " 'deceiver': 888,\n",
       " 'ruffini': 889,\n",
       " 'hardball': 890,\n",
       " 'laconic': 891,\n",
       " 'victorian-era': 892,\n",
       " 'complemented': 893,\n",
       " 'phew': 894,\n",
       " 'discard': 895,\n",
       " 'rewarded': 896,\n",
       " 'mentally-challenged': 897,\n",
       " 'mispronouncing': 898,\n",
       " 'non-criminal': 899,\n",
       " 'shot-for-shot': 900,\n",
       " 'fielder': 901,\n",
       " 'play': 902,\n",
       " 'shoulder-length': 903,\n",
       " 'simonesque': 904,\n",
       " 'cindy': 905,\n",
       " 'doubts': 906,\n",
       " \"'friend\": 907,\n",
       " 'portland': 908,\n",
       " 'drunk': 909,\n",
       " 'mainly': 910,\n",
       " 'decieving': 911,\n",
       " 'foreground': 912,\n",
       " 'heavenly': 913,\n",
       " 'quinland': 914,\n",
       " 'ex-gangsta': 915,\n",
       " 'likeness': 916,\n",
       " 'toro': 917,\n",
       " 'exchanged': 918,\n",
       " 'oilrig': 919,\n",
       " 'pistol': 920,\n",
       " 'outworld': 921,\n",
       " 'careen': 922,\n",
       " 'indescribable': 923,\n",
       " 'tsui': 924,\n",
       " 'dummy': 925,\n",
       " 'jawas': 926,\n",
       " 'clea': 927,\n",
       " 'stage': 928,\n",
       " 'antarctica': 929,\n",
       " 'thirtysomething': 930,\n",
       " 'bawling': 931,\n",
       " 'bears': 932,\n",
       " 'full-price': 933,\n",
       " 'bracing': 934,\n",
       " 'kennedy': 935,\n",
       " 'teachers': 936,\n",
       " 'reconsiders': 937,\n",
       " 'fetishized': 938,\n",
       " 'coolidge': 939,\n",
       " 'devote': 940,\n",
       " 'opts': 941,\n",
       " 'dreamer': 942,\n",
       " 'ferrari': 943,\n",
       " 'held': 944,\n",
       " 'maryam': 945,\n",
       " 'wizard': 946,\n",
       " 'hoggett': 947,\n",
       " 'signify': 948,\n",
       " 'contemptuous': 949,\n",
       " 'sliced': 950,\n",
       " 'titshots': 951,\n",
       " 'costuming': 952,\n",
       " 'handbook': 953,\n",
       " 'overfills': 954,\n",
       " 'unique': 955,\n",
       " 'crackles': 956,\n",
       " 'braga': 957,\n",
       " 'measurements': 958,\n",
       " 'favored': 959,\n",
       " 'scoundrels': 960,\n",
       " 'thigh-high': 961,\n",
       " 'naturally': 962,\n",
       " 'jimkendrick': 963,\n",
       " 'plimpton': 964,\n",
       " 'debris': 965,\n",
       " 'patronize': 966,\n",
       " 'necessity': 967,\n",
       " 'carrol': 968,\n",
       " 'anytime': 969,\n",
       " 'suppression': 970,\n",
       " 'pianist': 971,\n",
       " 'dorian': 972,\n",
       " 'overscore': 973,\n",
       " 'perking': 974,\n",
       " 'egoyan': 975,\n",
       " 'endora': 976,\n",
       " 'unacceptable': 977,\n",
       " 'insanely': 978,\n",
       " 'meerson': 979,\n",
       " 'eastwood-esque': 980,\n",
       " 'close-to-awful': 981,\n",
       " '15-year': 982,\n",
       " 'further': 983,\n",
       " '`come': 984,\n",
       " 'smuggle': 985,\n",
       " '_hard_ware': 986,\n",
       " 'purr': 987,\n",
       " 'cleopatra': 988,\n",
       " 'crust': 989,\n",
       " 'ismael': 990,\n",
       " 'gut-wrenching': 991,\n",
       " 'yuks': 992,\n",
       " 'occupants': 993,\n",
       " 'occurrences': 994,\n",
       " 'vulcan': 995,\n",
       " 'brody': 996,\n",
       " 'crunchily': 997,\n",
       " 'internet-like': 998,\n",
       " 'vulture-like': 999,\n",
       " 'child-support': 1000,\n",
       " ...}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_to_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excellent, we're much closer to being able to having our dataset in a form that TensorFlow can work with.  \n",
    "Just for sanity, let's see what the review above would look like as a list of the IDs above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[28510, 34424, 27745, 769, 40164, 18179, 14530, 8939, 32409, 19416]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[word_to_id[word] for word in nltk.tokenize.word_tokenize(df['review'][5])][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm going to trust that the above is mostly correct, but let's at least check that `moviemaking` matches the first index in the above list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28510"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_to_id[\"moviemaking\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perfect.  Now, let's convert all of the tokenized reviews into lists of `ID`s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_as_ids = []\n",
    "for review in df['review']:\n",
    "    reviews_as_ids.append([word_to_id[word] for word in nltk.tokenize.word_tokenize(review)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, as a sanity check, the 5th item in the `reviews_as_ids` list should be the same as the list that we see two cells above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[28510, 34424, 27745, 769, 40164, 18179, 14530, 8939, 32409, 19416]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_as_ids[4][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excellent, we have now transformed our dataset of movie reviews into a list of integers.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label Encoding\n",
    "Now, let's generate an array that we can use with TensorFlow from the labels in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pos</td>\n",
       "      <td>films adapted from comic books have had plenty...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pos</td>\n",
       "      <td>every now and then a movie comes along from a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pos</td>\n",
       "      <td>you've got mail works alot better than it dese...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pos</td>\n",
       "      <td>\" jaws \" is a rare film that grabs your atten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>pos</td>\n",
       "      <td>moviemaking is a lot like being the general ma...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                             review\n",
       "id                                                         \n",
       "1    pos  films adapted from comic books have had plenty...\n",
       "2    pos  every now and then a movie comes along from a ...\n",
       "3    pos  you've got mail works alot better than it dese...\n",
       "4    pos   \" jaws \" is a rare film that grabs your atten...\n",
       "5    pos  moviemaking is a lot like being the general ma..."
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>neg</td>\n",
       "      <td>if anything , \" stigmata \" should be taken as ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>neg</td>\n",
       "      <td>john boorman's \" zardoz \" is a goofy cinematic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>neg</td>\n",
       "      <td>the kids in the hall are an acquired taste .  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>neg</td>\n",
       "      <td>there was a time when john carpenter was a gre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>neg</td>\n",
       "      <td>two party guys bob their heads to haddaway's d...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                             review\n",
       "id                                                           \n",
       "1996   neg  if anything , \" stigmata \" should be taken as ...\n",
       "1997   neg  john boorman's \" zardoz \" is a goofy cinematic...\n",
       "1998   neg  the kids in the hall are an acquired taste .  ...\n",
       "1999   neg  there was a time when john carpenter was a gre...\n",
       "2000   neg  two party guys bob their heads to haddaway's d..."
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a list of the reviews which have been integer-tokenized, now let's generate a parallel numpy array of whether the review is positive or negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_labels = np.array(df['label'] == 'pos', dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_labels[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_labels[-5:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a sanity check, the length of this numpy array should be `2000`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(review_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Padding\n",
    "The reviews in our dataset contain a different length of tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f7519208080>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7519208fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.Series(reviews_as_ids).apply(len).hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of our reviews are under ~1,200 tokens long, and a few are over 2,500 tokens.\n",
    "\n",
    "The problem is that TensorFlow accepts only inputs of fixed length.  \n",
    "Further, LSTMs often have a practical limitation of only working with sequences that are a few hundred items long.\n",
    "\n",
    "This requires us to pick **a single token length** for our reviews as inputs.  \n",
    "Reviews which are shorter than this will be padded on the **right** with `0`s, and reviews which are longer will have to be truncated before being fed to TensorFlow.\n",
    "\n",
    "This is not as serious a limitation as it sounds, but it does have to be dealt with, or TensorFlow will throw errors during training.\n",
    "\n",
    "Accordingly, let's define a **sequence length** that we will fit every review into."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 200\n",
    "\n",
    "x = np.zeros((len(reviews_as_ids), seq_len), dtype=int)\n",
    "for i, review_as_id in enumerate(reviews_as_ids):\n",
    "    x[i, :len(review_as_id)] = np.array(review_as_id)[:seq_len]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shown below are two such sequences, one originally longer than the sequence length, and one shorter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([34629, 46469, 45217,  5444, 14530, 14327, 17706, 34629, 46469,\n",
       "        17969,  5444, 32708, 45347,   573, 41074,  7881, 33691, 14530,\n",
       "        38298, 27717,  8969,  8914, 19166, 18815, 33235, 28045, 33691,\n",
       "        28286, 14841, 39090, 27717,  8969, 38266, 11916, 18815, 40262,\n",
       "        19948, 33691, 35462, 27717,  8969, 17531, 17522, 18815,  4467,\n",
       "        11215, 20317, 33691, 33094,  5444, 14530, 18377, 27717,  8969,\n",
       "        29655, 15039,  6995, 17706, 41561, 34629, 46469,  5178, 14829,\n",
       "        32502, 18815, 34629, 46469, 36452, 39837, 45217, 14578, 24736,\n",
       "        21956, 10839, 32511, 24833,   877, 32511, 14530, 13935,  4467,\n",
       "        32422, 19416, 14530,  9430, 23150, 17706, 34629, 36452,   409,\n",
       "        38216, 45217, 14578, 24736, 36088, 14841, 34946, 29146, 18815,\n",
       "         4467, 38000, 12024, 38216, 41069, 38434, 30771, 27370, 17706,\n",
       "        44381, 14530, 14327, 17706, 14530,  2385, 19010,  7695, 18815,\n",
       "        14530, 17296, 36533, 19010,  6405, 38967, 18815, 14530, 35951,\n",
       "        39946, 19010, 30714, 18815,  4467,  8914, 19166, 14841, 11376,\n",
       "        31489, 19010,  7629, 32511, 12133, 39212, 17495,  8914,  3955,\n",
       "        17706, 42968, 12258, 14841, 25101, 27180, 36262, 18815,  4467,\n",
       "        34182, 34424, 12024,  9241, 12571,  2385,   573, 34182, 14841,\n",
       "        19063, 43756, 29139, 29579, 12024, 29139, 16885, 17706, 14530,\n",
       "        19842, 29337,  8969,  4180, 37275, 44902, 32511,  1669, 22036,\n",
       "         3404,  4467, 45525, 35626, 17706, 14530, 20177, 29327, 14492,\n",
       "        24736, 34424, 33235, 28045, 10646, 18815,  8969, 38266, 11916,\n",
       "        18815, 27745]),\n",
       " array([24736, 33072, 34424, 44544, 43976,  4467, 22737, 26570, 35208,\n",
       "        16943, 32511, 20886, 14829, 31137, 25040, 26229, 34182, 17706,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0]))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[31], x[1506]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Splitting and Shuffling\n",
    "\n",
    "Now that we have transformed our dataset into a format that TensorFlow can work with, we need to split the dataset into training, testing, and validation sets, so that we can better evaluate the model's performance.\n",
    "\n",
    "Let's use numpy to help us randomize here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use a seed for reproducibility of results\n",
    "np.random.seed(42)\n",
    "permute = np.random.permutation(range(len(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Generate shuffled versions of our data and labels\n",
    "x_shuffled = x[permute]\n",
    "y_shuffled = review_labels[permute]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use an 80% : 10% : 10% split into training : testing : validation sets\n",
    "train_split = int(0.8*len(x))\n",
    "test_split = int(0.9*len(x))\n",
    "\n",
    "train_x = x_shuffled[:train_split]\n",
    "test_x = x_shuffled[train_split:test_split]\n",
    "val_x = x_shuffled[test_split:]\n",
    "\n",
    "train_y = y_shuffled[:train_split]\n",
    "test_y = y_shuffled[train_split:test_split]\n",
    "val_y = y_shuffled[test_split:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a sanity check, recall that the original dataset was 1000 positive reviews followed by 1000 negative reviews.  \n",
    "If we've truly shuffled, then the beginning of each of the training, testing, and validation sets should be a mixture of positive or negative:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 1, 0, 0])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 1, 1, 0])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 1, 0])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_y[:6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a final sanity check, note that an 80%, 10%, 10% split should yield numpy arrays of size `1600`, `200`, and `200`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1600, 200, 200)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_x), len(test_x), len(val_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checkpointing\n",
    "We will use this opportunity to save our training, testing, and validation sets to disk, so that we can quickly load them in the future.\n",
    "\n",
    "Should this notebook need to be run in the future, it can start from the [Loading](#Loading) cells below.\n",
    "## Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"train_x\", train_x)\n",
    "np.save(\"train_y\", train_y)\n",
    "np.save(\"test_x\", test_x)\n",
    "np.save(\"test_y\", test_y)\n",
    "np.save(\"val_x\", val_x)\n",
    "np.save(\"val_y\", val_y)\n",
    "with open(\"review_word_set.pkl\", 'wb') as f:\n",
    "    pickle.dump(review_word_set, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = np.load(\"train_x.npy\")\n",
    "train_y = np.load(\"train_y.npy\")\n",
    "test_x = np.load(\"test_x.npy\")\n",
    "test_y = np.load(\"test_y.npy\")\n",
    "val_x = np.load(\"val_x.npy\")\n",
    "val_y = np.load(\"val_y.npy\")\n",
    "with open(\"review_word_set.pkl\", 'rb') as f:\n",
    "    review_word_set = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Architecture\n",
    "In this section, we will be defining a model architecture that we will use to \"learn\" the task of sentiment analysis.\n",
    "\n",
    "As a broad overview, this will be a neural network that takes a sequence as input, and produces a value of either 0 (a negative review) or 1 (a positive review).\n",
    "\n",
    "From the model's perspective, it will be seeing a vector of the above-defined **sequence length**, which is comprised of non-negative integers.\n",
    "\n",
    "After the input, the first layer of the model will be \"embedding\" these non-negative integers into a smaller representational space of only a few hundred floating-point numbers, to allow it to learn which sequences are important, and which are mere noise.\n",
    "\n",
    "Following this embedding layer, the \"embedded\" word vector will then pass into two parallel \"stacks\" of Long Short-Term Memory (LSTM) cells.\n",
    "\n",
    "The advantage of an LSTM cell is that, throughout time, it is able to remember better what came several dozen items earlier in the sequence than is a typical \"feed-forward\" network.  A broad overview of the machinery that allows an LSTM cell to accomplish this memory throughout a time sequence is shown below.\n",
    "![LSTM Cell, from colah's blog](http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-chain.png)\n",
    "\n",
    "Since our dataset is a sequence of words, it makes sense that the model would benefit from knowing about both the sequence going forward, and going backward.  Intuitively, the review \"This movie has everything that you would expect.  And nothing you wouldn't,\" starts off very positive, and only at the end of the sequence would we start to think that the review is negative.  Knowing that from the beginning would make parsing the sequence easier.  \n",
    "Language parsing is a [complicated task](https://research.googleblog.com/2016/05/announcing-syntaxnet-worlds-most.html) that is outside the scope of this notebook, but having this bi-directional parsing typically helps models to pick out what's important for sentiment classification.\n",
    "\n",
    "The bi-directional stacked LSTM architecture that we implement below will be similar to (though not exactly the same as) the following architecture:\n",
    "![bi-directional stacked LSTM, from WildML](http://www.wildml.com/wp-content/uploads/2015/09/Screen-Shot-2015-09-16-at-2.21.51-PM.png)\n",
    "\n",
    "In the above architecture, each successive black dot may be thought of as a token in our reviews.  After embedding this token, we then pass it to a forward group of LSTM cells, and a backward stack of LSTM cells (both in orange), and then perhaps to more of the same \"stacked\" on top, which then generates outputs (red) at the top.\n",
    "\n",
    "We then connect the red \"output\" cells to a single cell, since we want a single answer from the model, namely whether the given input review has a positive or a negative sentiment.\n",
    "\n",
    "Thankfully, TensorFlow provides an API to implement the above, which we will explore below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Placeholders\n",
    "Let's define the necessary placeholders in order for us to feed our pre-processed data from above into a TensorFlow model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/human/miniconda3/envs/ProofOfConcept/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = tf.Graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with graph.as_default():\n",
    "    # Define placeholders to accept batches of token-sequences\n",
    "    inputs = tf.placeholder(tf.int32, [None, None], name = \"inputs\")\n",
    "    labels = tf.placeholder(tf.int32, [None, None], name = \"labels\")\n",
    "    \n",
    "    # Define a placeholder to allow us to tweak the dropout hyperparameter\n",
    "    keep_prob = tf.placeholder(tf.float32, name=\"keep_prob\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding\n",
    "Many of the unique tokens that exist in our dataset, and thus have been assigned an `ID`, occur rarely.  \n",
    "Things that occur rarely don't give a deep learning model much chance to learn what they mean, and so generally they hurt performance unless we take special steps to combat them.\n",
    "\n",
    "As it turns out, we can probably condense the above ~47,000 unique tokens into a few hundred tokens, and still have the model perform well.  \n",
    "\n",
    "This is done through the use of an [\"embedding\"](https://www.tensorflow.org/versions/master/tutorials/seq2seq#embedding) layer, which lets our model decide which of the tokens it sees are important, and which are just noise.\n",
    "\n",
    "Thankfully, TensorFlow provides a compact way to define and use embeddings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size = 200\n",
    "\n",
    "with graph.as_default():\n",
    "    # Define an embedding that allows us to map our ~47,000 review tokens to our embedding size\n",
    "    # Our model will \"learn\" a good embedding during training\n",
    "    embedding = tf.Variable(tf.random_uniform((len(review_word_set) + 1, embedding_size), -1, 1), name=\"Embedding\")\n",
    "    embed = tf.nn.embedding_lookup(embedding, inputs, name=\"Embedding_Lookup\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder\n",
    "Now that we have defined an embedding to squash our input token sequences into a more manageable space, we now define an encoder that will be the heart of this bi-directional stacked LSTM model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_lstm_layers = 2\n",
    "num_lstm_units = 128\n",
    "\n",
    "with graph.as_default():\n",
    "    \n",
    "    def getLSTMlist(num_layers):\n",
    "        \"\"\"\n",
    "        Returns a list containing num_layers LSTM cells,\n",
    "        wrapped in dropout.\n",
    "        \n",
    "        This is to avoid TensorFlow syntax errors with the\n",
    "        [cell] * num_layers construction\n",
    "        \"\"\"\n",
    "        cell_list = []\n",
    "        for _ in range(num_layers):\n",
    "            # Your basic LSTM cell, with L2 regularization\n",
    "            lstm = tf.contrib.rnn.BasicLSTMCell(num_units=num_lstm_units)\n",
    "            \n",
    "            # Add dropout to the cell, using the keep_prob tensor\n",
    "            drop = tf.contrib.rnn.DropoutWrapper(lstm, output_keep_prob=keep_prob)\n",
    "            cell_list.append(drop)\n",
    "            \n",
    "        return cell_list\n",
    "    \n",
    "    forward_LSTMs = getLSTMlist(num_lstm_layers)\n",
    "    backward_LSTMs = getLSTMlist(num_lstm_layers)\n",
    "    \n",
    "    # Stack up multiple bidirectional LSTM layers\n",
    "    # Use dynamic to handle the unpacking of non-sequential input (embed)\n",
    "    outputs, output_state_fw, output_state_bw = \\\n",
    "        tf.contrib.rnn.stack_bidirectional_dynamic_rnn(forward_LSTMs, backward_LSTMs, embed, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorBoard visualizes the above as follows:  \n",
    "![stack_bidirectional_rnn](img/stack.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Function and Optimizer\n",
    "Finally, we will need to specify a loss function for our model so that it learns properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "alpha = 1e-2 # the factor by which to scale our L2 losses\n",
    "use_L2 = False\n",
    "\n",
    "with graph.as_default():\n",
    "    # Squash outputs to a single real number in the range of 0 to 1\n",
    "    predictions = tf.contrib.layers.fully_connected(outputs[:, -1], 1, activation_fn=tf.sigmoid)\n",
    "     \n",
    "    loss = tf.losses.mean_squared_error(labels, predictions)\n",
    "    \n",
    "    # Optimizer for training, using gradient clipping to control exploding gradients\n",
    "    tvars = tf.trainable_variables()\n",
    "    \n",
    "    # Get the L2 losses for weights, kernels, and biases, to discourage memorizing the training set\n",
    "    if use_L2:\n",
    "        for tensor in tvars:\n",
    "            if \"kernel\" in tensor.name or \"weights\" in tensor.name or \"bias\" in tensor.name:\n",
    "                loss += alpha * tf.nn.l2_loss(tensor)\n",
    "    \n",
    "    grads, _ = tf.clip_by_global_norm(tf.gradients(loss, tvars), 5) # clip gradients to 5\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate).minimize(loss, var_list=tvars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with graph.as_default():\n",
    "\n",
    "    ## Round our sigmoid [0,1] output to be either 0 or 1\n",
    "    predictions_integer = tf.cast(tf.round(predictions), tf.int32, name=\"Prediction_Integers\")\n",
    "\n",
    "    ## Define operations for {true, false} {positive, negative} predictions\n",
    "    TP = tf.count_nonzero(predictions_integer * labels, name='True_Positives', dtype=tf.int32)\n",
    "    TN = tf.count_nonzero((predictions_integer - 1) * (labels - 1), name=\"True_Negatives\", dtype=tf.int32)\n",
    "    FP = tf.count_nonzero(predictions_integer * (labels - 1), name=\"False_Positives\", dtype=tf.int32)\n",
    "    FN = tf.count_nonzero((predictions_integer - 1) * labels, name=\"False_Negatives\", dtype=tf.int32)\n",
    "\n",
    "    ## Define operations for accuracy, precision, recall, and F1 score\n",
    "\n",
    "    # accuracy ::= (TP + TN) / (TN + FN + TP + FP)\n",
    "    accuracy = tf.divide(TP + TN, TN + FN + TP + FP, name=\"Accuracy\")\n",
    "\n",
    "    # precision ::= TP / (TP + FP)\n",
    "    precision = tf.divide(TP, TP + FP, name=\"Precision\")\n",
    "\n",
    "    # recall::= TP / (TP + FN)\n",
    "    recall = tf.divide(TP, TP + FN, name=\"Recall\")\n",
    "\n",
    "    # F1 score ::= 2 * precision * recall / (precision + recall)\n",
    "    f1 = tf.divide((2 * precision * recall), (precision + recall), name=\"F1_score\")\n",
    "\n",
    "    # To also record this information in TensorBoard, we'll define scalar summaries here\n",
    "    with tf.name_scope('summaries'):\n",
    "        tf.summary.scalar('Loss', loss)\n",
    "        tf.summary.scalar('Accuracy', accuracy)\n",
    "        tf.summary.scalar('Precision', precision)\n",
    "        tf.summary.scalar('Recall', recall)\n",
    "        tf.summary.scalar('F1_score', f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the Model\n",
    "We're almost ready to start training our model.\n",
    "\n",
    "Before we begin training, let's define a function that we can use to generate batches of our training data, so that we don't risk running out of memory by loading everything into the model at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batches(x, y, batch_size=100):\n",
    "    '''\n",
    "    Given a set of features x, and a set of labels y,\n",
    "    return a generator yields shuffled batch_size tuples of x and y.\n",
    "    \n",
    "    Note that this function truncates x and y, if necessary,\n",
    "    so that it only returns full batches.\n",
    "    '''\n",
    "    ## Truncate x and y so that no batch is empty\n",
    "    num_batches = len(x) // batch_size\n",
    "    x, y = x[:num_batches * batch_size], y[:num_batches * batch_size]\n",
    "    \n",
    "    ## Shuffle x and y on the same index permutation\n",
    "    permute = np.random.permutation(range(len(x)))\n",
    "    x = x[permute]\n",
    "    y = y[permute]\n",
    "    \n",
    "    for i in range(0, len(x), batch_size):\n",
    "        yield x[i:i + batch_size], y[i:i + batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To keep our summary directories separate\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0/50 Iteration:    5 Training loss: 0.253 accuracy: 0.500 precision: 0.574 recall: 0.650 f1: 0.609\n",
      "Epoch:  0/50 Iteration:   10 Training loss: 0.256 accuracy: 0.440 precision: 0.477 recall: 0.585 f1: 0.525\n",
      "Epoch:  0/50 Iteration:   15 Training loss: 0.255 accuracy: 0.470 precision: 0.404 recall: 0.432 f1: 0.418\n",
      "Epoch:  1/50 Iteration:   20 Training loss: 0.246 accuracy: 0.590 precision: 0.672 recall: 0.661 f1: 0.667\n",
      "Epoch:  1/50 Iteration:   25 Training loss: 0.239 accuracy: 0.580 precision: 0.576 recall: 0.667 f1: 0.618\n",
      "                          Validation loss: 0.251 accuracy: 0.505 precision: 0.505 recall: 0.650 f1: 0.567\n",
      "Epoch:  1/50 Iteration:   30 Training loss: 0.241 accuracy: 0.620 precision: 0.569 recall: 0.717 f1: 0.635\n",
      "Epoch:  2/50 Iteration:   35 Training loss: 0.239 accuracy: 0.580 precision: 0.582 recall: 0.627 f1: 0.604\n",
      "Epoch:  2/50 Iteration:   40 Training loss: 0.227 accuracy: 0.650 precision: 0.638 recall: 0.815 f1: 0.715\n",
      "Epoch:  2/50 Iteration:   45 Training loss: 0.238 accuracy: 0.600 precision: 0.625 recall: 0.500 f1: 0.556\n",
      "Epoch:  3/50 Iteration:   50 Training loss: 0.210 accuracy: 0.660 precision: 0.600 recall: 0.682 f1: 0.638\n",
      "                          Validation loss: 0.254 accuracy: 0.545 precision: 0.543 recall: 0.624 f1: 0.581\n",
      "Epoch:  3/50 Iteration:   55 Training loss: 0.179 accuracy: 0.750 precision: 0.714 recall: 0.816 f1: 0.762\n",
      "Epoch:  3/50 Iteration:   60 Training loss: 0.151 accuracy: 0.810 precision: 0.764 recall: 0.875 f1: 0.816\n",
      "Epoch:  4/50 Iteration:   65 Training loss: 0.146 accuracy: 0.820 precision: 0.855 recall: 0.825 f1: 0.839\n",
      "Epoch:  4/50 Iteration:   70 Training loss: 0.140 accuracy: 0.790 precision: 0.830 recall: 0.750 f1: 0.788\n",
      "Epoch:  4/50 Iteration:   75 Training loss: 0.153 accuracy: 0.780 precision: 0.769 recall: 0.800 f1: 0.784\n",
      "                          Validation loss: 0.304 accuracy: 0.575 precision: 0.610 recall: 0.424 f1: 0.500\n",
      "Epoch:  4/50 Iteration:   80 Training loss: 0.122 accuracy: 0.830 precision: 0.850 recall: 0.864 f1: 0.857\n",
      "Epoch:  5/50 Iteration:   85 Training loss: 0.079 accuracy: 0.970 precision: 0.979 recall: 0.959 f1: 0.969\n",
      "Epoch:  5/50 Iteration:   90 Training loss: 0.090 accuracy: 0.870 precision: 0.870 recall: 0.887 f1: 0.879\n",
      "Epoch:  5/50 Iteration:   95 Training loss: 0.090 accuracy: 0.880 precision: 0.913 recall: 0.840 f1: 0.875\n",
      "Epoch:  6/50 Iteration:  100 Training loss: 0.047 accuracy: 0.940 precision: 0.959 recall: 0.922 f1: 0.940\n",
      "                          Validation loss: 0.348 accuracy: 0.525 precision: 0.526 recall: 0.597 f1: 0.558\n",
      "Epoch:  6/50 Iteration:  105 Training loss: 0.042 accuracy: 0.970 precision: 1.000 recall: 0.942 f1: 0.970\n",
      "Epoch:  6/50 Iteration:  110 Training loss: 0.040 accuracy: 0.960 precision: 0.976 recall: 0.930 f1: 0.952\n",
      "Epoch:  7/50 Iteration:  115 Training loss: 0.030 accuracy: 0.960 precision: 0.979 recall: 0.940 f1: 0.959\n",
      "Epoch:  7/50 Iteration:  120 Training loss: 0.050 accuracy: 0.930 precision: 0.889 recall: 0.980 f1: 0.932\n",
      "Epoch:  7/50 Iteration:  125 Training loss: 0.049 accuracy: 0.940 precision: 1.000 recall: 0.893 f1: 0.943\n",
      "                          Validation loss: 0.378 accuracy: 0.525 precision: 0.530 recall: 0.550 f1: 0.537\n",
      "Epoch:  8/50 Iteration:  130 Training loss: 0.016 accuracy: 0.990 precision: 0.977 recall: 1.000 f1: 0.988\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-57cefafd97bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m                     \u001b[0mlabels\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m                     keep_prob: train_keep_prob}\n\u001b[0;32m---> 25\u001b[0;31m             \u001b[0msummary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtr_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtr_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtr_prec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtr_rec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtr_f1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m                 \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmerged\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0mtrain_writer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ProofOfConcept/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ProofOfConcept/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ProofOfConcept/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ProofOfConcept/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ProofOfConcept/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "batch_size = 100\n",
    "train_keep_prob = 0.5\n",
    "\n",
    "# Define a time-stamped directory in which to keep the TensorBoard data for this run\n",
    "summaries_dir = \"./summaries/\" + datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "\n",
    "with graph.as_default():\n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    merged = tf.summary.merge_all()\n",
    "    train_writer = tf.summary.FileWriter(summaries_dir + '/train',\n",
    "                                          sess.graph)\n",
    "    test_writer = tf.summary.FileWriter(summaries_dir + '/test')\n",
    "    val_writer = tf.summary.FileWriter(summaries_dir + '/val')\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    iteration = 1\n",
    "    for e in range(epochs):\n",
    "        for x, y in get_batches(train_x, train_y, batch_size):\n",
    "            feed = {inputs: x,\n",
    "                    labels: y[:, None],\n",
    "                    keep_prob: train_keep_prob}\n",
    "            summary, tr_loss, tr_acc, tr_prec, tr_rec, tr_f1, _ = \\\n",
    "                sess.run([merged, loss, accuracy, precision, recall, f1, optimizer], feed_dict=feed)\n",
    "            train_writer.add_summary(summary, iteration)\n",
    "            \n",
    "            # Print training information\n",
    "            if iteration%5==0:\n",
    "                print(\"Epoch:{: 3d}/{}\".format(e, epochs),\n",
    "                      \"Iteration: {: 4d} Training\".format(iteration),\n",
    "                      \"loss: {:.3f}\".format(tr_loss),\n",
    "                     \"accuracy: {:.3f}\".format(tr_acc),\n",
    "                     \"precision: {:.3f}\".format(tr_prec),\n",
    "                     \"recall: {:.3f}\".format(tr_rec),\n",
    "                     \"f1: {:.3f}\".format(tr_f1))\n",
    "            \n",
    "            # Evaluate the validation set\n",
    "            if iteration%25==0:\n",
    "                running_stats = []\n",
    "                for x, y in get_batches(val_x, val_y, batch_size):\n",
    "                    feed = {inputs: x,\n",
    "                            labels: y[:, None],\n",
    "                            keep_prob: 1}\n",
    "                    summary, v_loss, v_acc, v_prec, v_rec, v_f1 = \\\n",
    "                        sess.run([merged, loss, accuracy, precision, recall, f1], feed_dict=feed)\n",
    "                    val_writer.add_summary(summary, iteration)\n",
    "                    running_stats.append([v_loss, v_acc, v_prec, v_rec, v_f1])\n",
    "                running_stats = np.array(running_stats)\n",
    "                val_averages = running_stats.mean(axis=0)\n",
    "                print(\" \"*25,\n",
    "                      \"Validation loss: {:.3f}\".format(val_averages[0]),\n",
    "                     \"accuracy: {:.3f}\".format(val_averages[1]),\n",
    "                     \"precision: {:.3f}\".format(val_averages[2]),\n",
    "                     \"recall: {:.3f}\".format(val_averages[3]),\n",
    "                     \"f1: {:.3f}\".format(val_averages[4]))\n",
    "            iteration +=1\n",
    "    saver.save(sess, \"checkpoints/sentiment.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Performance\n",
    "Below are some screen captures from TensorBoard, to show how the model's Accuracy, Precision, Recall, F1 Score, and Loss progressed on the training and validation sets during training:  \n",
    "**Photo goes here**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's see how our model performed on the test set that we held out earlier.\n",
    "\n",
    "In order to do this, we will plot a \"confusion matrix,\" which concisely displays how many false positives, false negatives, true positives, and true negatives the model yielded.\n",
    "\n",
    "First, let's define our helper code for printing a confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \n",
    "    http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html#sphx-glr-auto-examples-model-selection-plot-confusion-matrix-py\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.3f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.8  0.2]\n",
      " [ 0.4  0.6]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f714541da90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cnf_matrix = np.array([[8,2],[8,12]])\n",
    "# [TP, FN], [FP, TN]\n",
    "class_names = [\"Positive\", \"Negative\"]\n",
    "\n",
    "np.set_printoptions(precision=3)\n",
    "# Plot normalized confusion matrix\n",
    "\n",
    "plt.Figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names, normalize=True,\n",
    "                      title='Normalized confusion matrix, Dummy Values')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's reload our model from disk, and run it on the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints/sentiment.ckpt\n",
      "Test loss: 0.337 accuracy: 0.595 precision: 0.497 recall: 0.675 f1: 0.570\n"
     ]
    }
   ],
   "source": [
    "running_stats = []\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    saver.restore(sess, tf.train.latest_checkpoint('checkpoints'))\n",
    "    conf_mat = np.zeros(4, dtype=int)\n",
    "    running_stats = []\n",
    "    for i, (x, y) in enumerate(get_batches(test_x, test_y, batch_size), 1):\n",
    "        feed = {inputs: x,\n",
    "                labels: y[:, None],\n",
    "                keep_prob: 1}\n",
    "        v_loss, v_acc, v_prec, v_rec, v_f1, true_pos, false_neg, false_pos, true_neg = \\\n",
    "            sess.run([loss, accuracy, precision, recall, f1, TP, FN, FP, TN], feed_dict=feed)\n",
    "        running_stats.append([v_loss, v_acc, v_prec, v_rec, v_f1])\n",
    "        conf_mat += (true_pos, true_neg, false_pos, false_neg)\n",
    "        \n",
    "    running_stats = np.array(running_stats)\n",
    "    test_averages = running_stats.mean(axis=0)\n",
    "    print(\"Test loss: {:.3f}\".format(test_averages[0]),\n",
    "                 \"accuracy: {:.3f}\".format(test_averages[1]),\n",
    "                 \"precision: {:.3f}\".format(test_averages[2]),\n",
    "                 \"recall: {:.3f}\".format(test_averages[3]),\n",
    "                 \"f1: {:.3f}\".format(test_averages[4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.519  0.481]\n",
      " [ 0.728  0.272]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f852417d160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Reshape into 2 x 2 matrix\n",
    "conf_mat = conf_mat.reshape((2,2))\n",
    "\n",
    "class_names = [\"Positive\", \"Negative\"]\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "\n",
    "plt.Figure()\n",
    "plot_confusion_matrix(conf_mat, classes=class_names, normalize=True,\n",
    "                      title='Normalized confusion matrix, Test Set')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
